{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3d-scatter-tupac-with-mac.html\n",
      "AskWhai Data Challenge.ipynb\n",
      "Association Rule Analysis.ipynb\n",
      "D3 Tree Map\n",
      "EDA-Insights.ipynb\n",
      "Feature Engineering and Modeling.ipynb\n",
      "aisles.csv\n",
      "association_result.csv\n",
      "check notebook.ipynb\n",
      "da_count.csv\n",
      "da_order.csv\n",
      "dataset\n",
      "depart_aisle_count.csv\n",
      "depart_aisle_order.csv\n",
      "departments.csv\n",
      "mydf.csv\n",
      "order_products__prior.csv\n",
      "order_products__test_cap.csv\n",
      "order_products__train_cap.csv\n",
      "orders.csv\n",
      "products.csv\n",
      "products_new.csv\n",
      "summary.csv\n",
      "train_data.csv\n",
      "treemap_order.png\n",
      "treemap_products.png\n",
      "user_all.csv\n",
      "users.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import gc\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_data):\n",
    "    '''\n",
    "    --------------------------------order_product--------------------------------\n",
    "    * Unique in order_id + product_id\n",
    "    '''\n",
    "    priors = pd.read_csv(path_data + 'order_products__prior.csv', \n",
    "                     dtype={\n",
    "                            'order_id': np.int32,\n",
    "                            'product_id': np.uint16,\n",
    "                            'add_to_cart_order': np.int16,\n",
    "                            'reordered': np.int8})\n",
    "    train = pd.read_csv(path_data + 'order_products__train_cap.csv', \n",
    "                    dtype={\n",
    "                            'order_id': np.int32,\n",
    "                            'product_id': np.uint16,\n",
    "                            'add_to_cart_order': np.int16,\n",
    "                            'reordered': np.int8})\n",
    "    '''\n",
    "    --------------------------------order--------------------------------\n",
    "    * This file tells us which set (prior, train, test) an order belongs\n",
    "    * Unique in order_id\n",
    "    * order_id in train, prior, test has no intersection\n",
    "    * this is the #order_number order of this user\n",
    "    '''\n",
    "    orders = pd.read_csv(path_data + 'orders.csv', \n",
    "                         dtype={\n",
    "                                'order_id': np.int32,\n",
    "                                'user_id': np.int64,\n",
    "                                'eval_set': 'category',\n",
    "                                'order_number': np.int16,\n",
    "                                'order_dow': np.int8,\n",
    "                                'order_hour_of_day': np.int8,\n",
    "                                'days_since_prior_order': np.float32})\n",
    "\n",
    "    #  order in prior, train, test has no duplicate\n",
    "    #  order_ids_pri = priors.order_id.unique()\n",
    "    #  order_ids_trn = train.order_id.unique()\n",
    "    #  order_ids_tst = orders[orders.eval_set == 'test']['order_id'].unique()\n",
    "    #  print(set(order_ids_pri).intersection(set(order_ids_trn)))\n",
    "    #  print(set(order_ids_pri).intersection(set(order_ids_tst)))\n",
    "    #  print(set(order_ids_trn).intersection(set(order_ids_tst)))\n",
    "\n",
    "    '''\n",
    "    --------------------------------product--------------------------------\n",
    "    * Unique in product_id\n",
    "    '''\n",
    "    products = pd.read_csv(path_data + 'products.csv')\n",
    "    aisles = pd.read_csv(path_data + \"aisles.csv\")\n",
    "    departments = pd.read_csv(path_data + \"departments.csv\")\n",
    "    \n",
    "    return priors, train, orders, products, aisles, departments\n",
    "\n",
    "class tick_tock:\n",
    "    def __init__(self, process_name, verbose=1):\n",
    "        self.process_name = process_name\n",
    "        self.verbose = verbose\n",
    "    def __enter__(self):\n",
    "        if self.verbose:\n",
    "            print(self.process_name + \" begin ......\")\n",
    "            self.begin_time = time.time()\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        if self.verbose:\n",
    "            end_time = time.time()\n",
    "            print(self.process_name + \" end ......\")\n",
    "            print('time lapsing {0} s \\n'.format(end_time - self.begin_time))\n",
    "            \n",
    "def ka_add_groupby_features_1_vs_n(df, group_columns_list, agg_dict, only_new_feature=True):\n",
    "    '''Create statistical columns, group by [N columns] and compute stats on [N column]\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       df: pandas dataframe\n",
    "          Features matrix\n",
    "       group_columns_list: list_like\n",
    "          List of columns you want to group with, could be multiple columns\n",
    "       agg_dict: python dictionary\n",
    "\n",
    "       Return\n",
    "       ------\n",
    "       new pandas dataframe with original columns and new added columns\n",
    "\n",
    "       Example\n",
    "       -------\n",
    "       {real_column_name: {your_specified_new_column_name : method}}\n",
    "       agg_dict = {'user_id':{'prod_tot_cnts':'count'},\n",
    "                   'reordered':{'reorder_tot_cnts_of_this_prod':'sum'},\n",
    "                   'user_buy_product_times': {'prod_order_once':lambda x: sum(x==1),\n",
    "                                              'prod_order_more_than_once':lambda x: sum(x==2)}}\n",
    "       ka_add_stats_features_1_vs_n(train, ['product_id'], agg_dict)\n",
    "    '''\n",
    "    with tick_tock(\"add stats features\"):\n",
    "        try:\n",
    "            if type(group_columns_list) == list:\n",
    "                pass\n",
    "            else:\n",
    "                raise TypeError(k + \"should be a list\")\n",
    "        except TypeError as e:\n",
    "            print(e)\n",
    "            raise\n",
    "\n",
    "        df_new = df.copy()\n",
    "        grouped = df_new.groupby(group_columns_list)\n",
    "\n",
    "        the_stats = grouped.agg(agg_dict)\n",
    "        the_stats.columns = the_stats.columns.droplevel(0)\n",
    "        the_stats.reset_index(inplace=True)\n",
    "        if only_new_feature:\n",
    "            df_new = the_stats\n",
    "        else:\n",
    "            df_new = pd.merge(left=df_new, right=the_stats, on=group_columns_list, how='left')\n",
    "\n",
    "    return df_new\n",
    "\n",
    "def ka_add_groupby_features_n_vs_1(df, group_columns_list, target_columns_list, methods_list, keep_only_stats=True, verbose=1):\n",
    "    '''Create statistical columns, group by [N columns] and compute stats on [1 column]\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       df: pandas dataframe\n",
    "          Features matrix\n",
    "       group_columns_list: list_like\n",
    "          List of columns you want to group with, could be multiple columns\n",
    "       target_columns_list: list_like\n",
    "          column you want to compute stats, need to be a list with only one element\n",
    "       methods_list: list_like\n",
    "          methods that you want to use, all methods that supported by groupby in Pandas\n",
    "\n",
    "       Return\n",
    "       ------\n",
    "       new pandas dataframe with original columns and new added columns\n",
    "\n",
    "       Example\n",
    "       -------\n",
    "       ka_add_stats_features_n_vs_1(train, group_columns_list=['x0'], target_columns_list=['x10'])\n",
    "    '''\n",
    "    with tick_tock(\"add stats features\", verbose):\n",
    "        dicts = {\"group_columns_list\": group_columns_list , \"target_columns_list\": target_columns_list, \"methods_list\" :methods_list}\n",
    "\n",
    "        for k, v in dicts.items():\n",
    "            try:\n",
    "                if type(v) == list:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise TypeError(k + \"should be a list\")\n",
    "            except TypeError as e:\n",
    "                print(e)\n",
    "                raise\n",
    "\n",
    "        grouped_name = ''.join(group_columns_list)\n",
    "        target_name = ''.join(target_columns_list)\n",
    "        combine_name = [[grouped_name] + [method_name] + [target_name] for method_name in methods_list]\n",
    "\n",
    "        df_new = df.copy()\n",
    "        grouped = df_new.groupby(group_columns_list)\n",
    "\n",
    "        the_stats = grouped[target_name].agg(methods_list).reset_index()\n",
    "        the_stats.columns = [grouped_name] + \\\n",
    "                            ['_%s_%s_by_%s' % (grouped_name, method_name, target_name) \\\n",
    "                             for (grouped_name, method_name, target_name) in combine_name]\n",
    "        if keep_only_stats:\n",
    "            return the_stats\n",
    "        else:\n",
    "            df_new = pd.merge(left=df_new, right=the_stats, on=group_columns_list, how='left')\n",
    "        return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = './'\n",
    "priors, train, orders, products, aisles, departments = load_data(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features begin ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuechunwang/.local/lib/python3.6/site-packages/pandas/core/groupby/generic.py:1455: FutureWarning: using a dict with renaming is deprecated and will be removed\n",
      "in a future version.\n",
      "\n",
      "For column-specific groupby renaming, use named aggregation\n",
      "\n",
      "    >>> df.groupby(...).agg(name=('column', aggfunc))\n",
      "\n",
      "  return super().aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features end ......\n",
      "time lapsing 46.15955090522766 s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Products information ----------------------------------------------------------------\n",
    "# add order information to priors set\n",
    "priors_orders_detail = orders.merge(right=priors, how='inner', on='order_id')\n",
    "\n",
    "# create new variables\n",
    "# _user_buy_product_times: 用户是第几次购买该商品\n",
    "priors_orders_detail.loc[:,'_user_buy_product_times'] = priors_orders_detail.groupby(['user_id', 'product_id']).cumcount() + 1\n",
    "# _prod_tot_cnts: 该商品被购买的总次数,表明被喜欢的程度\n",
    "# _reorder_tot_cnts_of_this_prod: 这件商品被再次购买的总次数\n",
    "### 我觉得下面两个很不好理解，考虑改变++++++++++++++++++++++++++\n",
    "# _prod_order_once: 该商品被购买一次的总次数\n",
    "# _prod_order_more_than_once: 该商品被购买一次以上的总次数\n",
    "agg_dict = {'user_id':{'_prod_tot_cnts':'count'}, \n",
    "            'reordered':{'_prod_reorder_tot_cnts':'sum'}, \n",
    "            '_user_buy_product_times': {'_prod_buy_first_time_total_cnt':lambda x: sum(x==1),\n",
    "                                        '_prod_buy_second_time_total_cnt':lambda x: sum(x==2)}}\n",
    "prd = ka_add_groupby_features_1_vs_n(priors_orders_detail, ['product_id'], agg_dict)\n",
    "\n",
    "# _prod_reorder_prob: 这个指标不好理解\n",
    "# _prod_reorder_ratio: 商品复购率\n",
    "prd['_prod_reorder_prob'] = prd._prod_buy_second_time_total_cnt / prd._prod_buy_first_time_total_cnt\n",
    "prd['_prod_reorder_ratio'] = prd._prod_reorder_tot_cnts / prd._prod_tot_cnts\n",
    "prd['_prod_reorder_times'] = 1 + prd._prod_reorder_tot_cnts / prd._prod_buy_first_time_total_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>_prod_tot_cnts</th>\n",
       "      <th>_prod_reorder_tot_cnts</th>\n",
       "      <th>_prod_buy_first_time_total_cnt</th>\n",
       "      <th>_prod_buy_second_time_total_cnt</th>\n",
       "      <th>_prod_reorder_prob</th>\n",
       "      <th>_prod_reorder_ratio</th>\n",
       "      <th>_prod_reorder_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1852</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>716</td>\n",
       "      <td>276</td>\n",
       "      <td>0.385475</td>\n",
       "      <td>0.613391</td>\n",
       "      <td>2.586592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>12.0</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>277</td>\n",
       "      <td>203.0</td>\n",
       "      <td>74</td>\n",
       "      <td>36</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.732852</td>\n",
       "      <td>3.743243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>329</td>\n",
       "      <td>147.0</td>\n",
       "      <td>182</td>\n",
       "      <td>64</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>1.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  _prod_tot_cnts  _prod_reorder_tot_cnts  \\\n",
       "0           1            1852                  1136.0   \n",
       "1           2              90                    12.0   \n",
       "2           3             277                   203.0   \n",
       "3           4             329                   147.0   \n",
       "4           5              15                     9.0   \n",
       "\n",
       "   _prod_buy_first_time_total_cnt  _prod_buy_second_time_total_cnt  \\\n",
       "0                             716                              276   \n",
       "1                              78                                8   \n",
       "2                              74                               36   \n",
       "3                             182                               64   \n",
       "4                               6                                4   \n",
       "\n",
       "   _prod_reorder_prob  _prod_reorder_ratio  _prod_reorder_times  \n",
       "0            0.385475             0.613391             2.586592  \n",
       "1            0.102564             0.133333             1.153846  \n",
       "2            0.486486             0.732852             3.743243  \n",
       "3            0.351648             0.446809             1.807692  \n",
       "4            0.666667             0.600000             2.500000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd.to_csv('prd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features begin ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuechunwang/.local/lib/python3.6/site-packages/pandas/core/groupby/generic.py:1455: FutureWarning: using a dict with renaming is deprecated and will be removed\n",
      "in a future version.\n",
      "\n",
      "For column-specific groupby renaming, use named aggregation\n",
      "\n",
      "    >>> df.groupby(...).agg(name=('column', aggfunc))\n",
      "\n",
      "  return super().aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features end ......\n",
      "time lapsing 0.4147629737854004 s \n",
      "\n",
      "add stats features begin ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuechunwang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/xuechunwang/.local/lib/python3.6/site-packages/pandas/core/indexing.py:961: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  return getattr(section, self.name)[new_key]\n",
      "/Users/xuechunwang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features end ......\n",
      "time lapsing 620.6549649238586 s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# _user_total_orders: 用户的总订单数\n",
    "# 可以考虑加入其它统计指标++++++++++++++++++++++++++\n",
    "# _user_sum_days_since_prior_order: 距离上次购买时间(和),这个只能在orders表里面计算，priors_orders_detail不是在order level上面unique\n",
    "# _user_mean_days_since_prior_order: 距离上次购买时间(均值)\n",
    "agg_dict_2 = {'order_number':{'_user_total_orders':'max'},\n",
    "              'days_since_prior_order':{'_user_sum_days_since_prior_order':'sum', \n",
    "                                        '_user_mean_days_since_prior_order': 'mean'}}\n",
    "users = ka_add_groupby_features_1_vs_n(orders[orders.eval_set == 'prior'], ['user_id'], agg_dict_2)\n",
    "\n",
    "# _user_reorder_ratio: reorder的总次数 / 第一单后买后的总次数\n",
    "# _user_total_products: 用户购买的总商品数\n",
    "# _user_distinct_products: 用户购买的unique商品数\n",
    "agg_dict_3 = {'reordered':\n",
    "              {'_user_reorder_ratio': \n",
    "               lambda x: sum(priors_orders_detail.ix[x.index,'reordered']==1)/\n",
    "                         sum(priors_orders_detail.ix[x.index,'order_number'] > 1)},\n",
    "              'product_id':{'_user_total_products':'count', \n",
    "                            '_user_distinct_products': lambda x: x.nunique()}}\n",
    "us = ka_add_groupby_features_1_vs_n(priors_orders_detail, ['user_id'], agg_dict_3)\n",
    "users = users.merge(us, how='inner')\n",
    "\n",
    "# 平均每单的商品数\n",
    "# 每单中最多的商品数，最少的商品数++++++++++++++\n",
    "users['_user_average_basket'] = users._user_total_products / users._user_total_orders\n",
    "\n",
    "us = orders[orders.eval_set != \"prior\"][['user_id', 'order_id', 'eval_set', 'days_since_prior_order']]\n",
    "us.rename(index=str, columns={'days_since_prior_order': 'time_since_last_order'}, inplace=True)\n",
    "\n",
    "users = users.merge(us, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>_user_total_orders</th>\n",
       "      <th>_user_sum_days_since_prior_order</th>\n",
       "      <th>_user_mean_days_since_prior_order</th>\n",
       "      <th>_user_reorder_ratio</th>\n",
       "      <th>_user_total_products</th>\n",
       "      <th>_user_distinct_products</th>\n",
       "      <th>_user_average_basket</th>\n",
       "      <th>order_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>time_since_last_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>176.0</td>\n",
       "      <td>19.555555</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>1187899</td>\n",
       "      <td>train</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>198.0</td>\n",
       "      <td>15.230769</td>\n",
       "      <td>0.510989</td>\n",
       "      <td>195</td>\n",
       "      <td>102</td>\n",
       "      <td>13.928571</td>\n",
       "      <td>1492625</td>\n",
       "      <td>train</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>133.0</td>\n",
       "      <td>12.090909</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>2774568</td>\n",
       "      <td>test</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>329954</td>\n",
       "      <td>test</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>2196797</td>\n",
       "      <td>train</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  _user_total_orders  _user_sum_days_since_prior_order  \\\n",
       "0        1                  10                             176.0   \n",
       "1        2                  14                             198.0   \n",
       "2        3                  12                             133.0   \n",
       "3        4                   5                              55.0   \n",
       "4        5                   4                              40.0   \n",
       "\n",
       "   _user_mean_days_since_prior_order  _user_reorder_ratio  \\\n",
       "0                          19.555555             0.759259   \n",
       "1                          15.230769             0.510989   \n",
       "2                          12.090909             0.705128   \n",
       "3                          13.750000             0.071429   \n",
       "4                          13.333333             0.538462   \n",
       "\n",
       "   _user_total_products  _user_distinct_products  _user_average_basket  \\\n",
       "0                    59                       18              5.900000   \n",
       "1                   195                      102             13.928571   \n",
       "2                    88                       33              7.333333   \n",
       "3                    18                       17              3.600000   \n",
       "4                    37                       23              9.250000   \n",
       "\n",
       "   order_id eval_set  time_since_last_order  \n",
       "0   1187899    train                   14.0  \n",
       "1   1492625    train                   30.0  \n",
       "2   2774568     test                   11.0  \n",
       "3    329954     test                   30.0  \n",
       "4   2196797    train                    6.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv('users_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features begin ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuechunwang/.local/lib/python3.6/site-packages/pandas/core/groupby/generic.py:1455: FutureWarning: using a dict with renaming is deprecated and will be removed\n",
      "in a future version.\n",
      "\n",
      "For column-specific groupby renaming, use named aggregation\n",
      "\n",
      "    >>> df.groupby(...).agg(name=('column', aggfunc))\n",
      "\n",
      "  return super().aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features end ......\n",
      "time lapsing 45.9518609046936 s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 这里应该还有很多变量可以被添加\n",
    "# _up_order_count: 用户购买该商品的次数\n",
    "# _up_first_order_number: 用户第一次购买该商品所处的订单数\n",
    "# _up_last_order_number: 用户最后一次购买该商品所处的订单数\n",
    "# _up_average_cart_position: 该商品被添加到购物篮中的平均位置\n",
    "agg_dict_4 = {'order_number':{'_up_order_count': 'count', \n",
    "                              '_up_first_order_number': 'min', \n",
    "                              '_up_last_order_number':'max'}, \n",
    "              'add_to_cart_order':{'_up_average_cart_position': 'mean'}}\n",
    "\n",
    "data = ka_add_groupby_features_1_vs_n(df=priors_orders_detail, \n",
    "                                                      group_columns_list=['user_id', 'product_id'], \n",
    "                                                      agg_dict=agg_dict_4)\n",
    "\n",
    "data = data.merge(prd, how='inner', on='product_id').merge(users, how='inner', on='user_id')\n",
    "# 该商品购买次数 / 总的订单数\n",
    "# 最近一次购买商品 - 最后一次购买该商品\n",
    "# 该商品购买次数 / 第一次购买该商品到最后一次购买商品的的订单数\n",
    "data['_up_order_rate'] = data._up_order_count / data._user_total_orders\n",
    "data['_up_order_since_last_order'] = data._user_total_orders - data._up_last_order_number\n",
    "data['_up_order_rate_since_first_order'] = data._up_order_count / (data._user_total_orders - data._up_first_order_number + 1)\n",
    "\n",
    "# add user_id to train set\n",
    "train = train.merge(right=orders[['order_id', 'user_id']], how='left', on='order_id')\n",
    "data = data.merge(train[['user_id', 'product_id', 'reordered']], on=['user_id', 'product_id'], how='left')\n",
    "\n",
    "# release Memory\n",
    "# del train, prd, users\n",
    "# gc.collect()\n",
    "# release Memory\n",
    "# del priors_orders_detail, orders\n",
    "# gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>_up_order_count</th>\n",
       "      <th>_up_first_order_number</th>\n",
       "      <th>_up_last_order_number</th>\n",
       "      <th>_up_average_cart_position</th>\n",
       "      <th>_prod_tot_cnts</th>\n",
       "      <th>_prod_reorder_tot_cnts</th>\n",
       "      <th>_prod_buy_first_time_total_cnt</th>\n",
       "      <th>_prod_buy_second_time_total_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>_user_total_products</th>\n",
       "      <th>_user_distinct_products</th>\n",
       "      <th>_user_average_basket</th>\n",
       "      <th>order_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>time_since_last_order</th>\n",
       "      <th>_up_order_rate</th>\n",
       "      <th>_up_order_since_last_order</th>\n",
       "      <th>_up_order_rate_since_first_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>35791</td>\n",
       "      <td>27791.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>4660</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1187899</td>\n",
       "      <td>train</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1946</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>557</td>\n",
       "      <td>308</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1187899</td>\n",
       "      <td>train</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5526</td>\n",
       "      <td>3603.0</td>\n",
       "      <td>1923</td>\n",
       "      <td>1003</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1187899</td>\n",
       "      <td>train</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>6476</td>\n",
       "      <td>4797.0</td>\n",
       "      <td>1679</td>\n",
       "      <td>889</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1187899</td>\n",
       "      <td>train</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>3751</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>1286</td>\n",
       "      <td>617</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1187899</td>\n",
       "      <td>train</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  _up_order_count  _up_first_order_number  \\\n",
       "0        1         196               10                       1   \n",
       "1        1       10258                9                       2   \n",
       "2        1       10326                1                       5   \n",
       "3        1       12427               10                       1   \n",
       "4        1       13032                3                       2   \n",
       "\n",
       "   _up_last_order_number  _up_average_cart_position  _prod_tot_cnts  \\\n",
       "0                     10                   1.400000           35791   \n",
       "1                     10                   3.333333            1946   \n",
       "2                      5                   5.000000            5526   \n",
       "3                     10                   3.300000            6476   \n",
       "4                     10                   6.333333            3751   \n",
       "\n",
       "   _prod_reorder_tot_cnts  _prod_buy_first_time_total_cnt  \\\n",
       "0                 27791.0                            8000   \n",
       "1                  1389.0                             557   \n",
       "2                  3603.0                            1923   \n",
       "3                  4797.0                            1679   \n",
       "4                  2465.0                            1286   \n",
       "\n",
       "   _prod_buy_second_time_total_cnt  ...  _user_total_products  \\\n",
       "0                             4660  ...                    59   \n",
       "1                              308  ...                    59   \n",
       "2                             1003  ...                    59   \n",
       "3                              889  ...                    59   \n",
       "4                              617  ...                    59   \n",
       "\n",
       "   _user_distinct_products  _user_average_basket  order_id  eval_set  \\\n",
       "0                       18                   5.9   1187899     train   \n",
       "1                       18                   5.9   1187899     train   \n",
       "2                       18                   5.9   1187899     train   \n",
       "3                       18                   5.9   1187899     train   \n",
       "4                       18                   5.9   1187899     train   \n",
       "\n",
       "   time_since_last_order  _up_order_rate  _up_order_since_last_order  \\\n",
       "0                   14.0             1.0                           0   \n",
       "1                   14.0             0.9                           0   \n",
       "2                   14.0             0.1                           5   \n",
       "3                   14.0             1.0                           0   \n",
       "4                   14.0             0.3                           0   \n",
       "\n",
       "   _up_order_rate_since_first_order  reordered  \n",
       "0                          1.000000        NaN  \n",
       "1                          1.000000        NaN  \n",
       "2                          0.166667        NaN  \n",
       "3                          1.000000        NaN  \n",
       "4                          0.333333        NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "train = data.loc[data.eval_set == \"train\",:]\n",
    "train.drop(['eval_set', 'user_id', 'product_id', 'order_id'], axis=1, inplace=True)\n",
    "train.loc[:, 'reordered'] = train.reordered.fillna(0)\n",
    "\n",
    "X_test = data.loc[data.eval_set == \"test\",:]\n",
    "\n",
    "# subsample 让training时间更短\n",
    "X_train, X_val, y_train, y_val = train_test_split(train.drop('reordered', axis=1), train.reordered,\n",
    "                                                    test_size=0.9, random_state=42)\n",
    "d_train = xgboost.DMatrix(X_train, y_train)\n",
    "xgb_params = {\n",
    "    \"objective\"         : \"reg:logistic\"\n",
    "    ,\"eval_metric\"      : \"logloss\"\n",
    "    ,\"eta\"              : 0.1\n",
    "    ,\"max_depth\"        : 6\n",
    "    ,\"min_child_weight\" :10\n",
    "    ,\"gamma\"            :0.70\n",
    "    ,\"subsample\"        :0.76\n",
    "    ,\"colsample_bytree\" :0.95\n",
    "    ,\"alpha\"            :2e-05\n",
    "    ,\"lambda\"           :10\n",
    "}\n",
    "\n",
    "watchlist= [(d_train, \"train\")]\n",
    "bst = xgboost.train(params=xgb_params, dtrain=d_train, num_boost_round=80, evals=watchlist, verbose_eval=10)\n",
    "xgboost.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuechunwang/.local/lib/python3.6/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/Users/xuechunwang/.local/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train = data.loc[data.eval_set == \"train\",:]\n",
    "train.drop(['eval_set', 'user_id', 'product_id', 'order_id'], axis=1, inplace=True)\n",
    "train.loc[:, 'reordered'] = train.reordered.fillna(0)\n",
    "\n",
    "X_test = data.loc[data.eval_set == \"test\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_up_order_count', '_up_first_order_number', '_up_last_order_number',\n",
       "       '_up_average_cart_position', '_prod_tot_cnts', '_prod_reorder_tot_cnts',\n",
       "       '_prod_buy_first_time_total_cnt', '_prod_buy_second_time_total_cnt',\n",
       "       '_prod_reorder_prob', '_prod_reorder_ratio', '_prod_reorder_times',\n",
       "       '_user_total_orders', '_user_sum_days_since_prior_order',\n",
       "       '_user_mean_days_since_prior_order', '_user_reorder_ratio',\n",
       "       '_user_total_products', '_user_distinct_products',\n",
       "       '_user_average_basket', 'time_since_last_order', '_up_order_rate',\n",
       "       '_up_order_since_last_order', '_up_order_rate_since_first_order',\n",
       "       'reordered'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 4904100,\n",
       " 2: 1292622,\n",
       " 3: 579575,\n",
       " 4: 317640,\n",
       " 5: 195887,\n",
       " 6: 130667,\n",
       " 7: 91664,\n",
       " 8: 67020,\n",
       " 9: 50395,\n",
       " 10: 38695,\n",
       " 11: 30562,\n",
       " 12: 24180,\n",
       " 13: 19821,\n",
       " 14: 16091,\n",
       " 15: 13110,\n",
       " 16: 11080,\n",
       " 17: 9073,\n",
       " 18: 7931,\n",
       " 19: 6669,\n",
       " 20: 5652,\n",
       " 21: 4752,\n",
       " 22: 4206,\n",
       " 23: 3609,\n",
       " 24: 3203,\n",
       " 25: 2756,\n",
       " 26: 2557,\n",
       " 27: 2168,\n",
       " 28: 1872,\n",
       " 29: 1653,\n",
       " 30: 1460,\n",
       " 31: 1304,\n",
       " 32: 1104,\n",
       " 33: 1002,\n",
       " 34: 917,\n",
       " 35: 789,\n",
       " 36: 745,\n",
       " 37: 611,\n",
       " 38: 592,\n",
       " 39: 523,\n",
       " 40: 471,\n",
       " 41: 407,\n",
       " 42: 337,\n",
       " 43: 354,\n",
       " 44: 316,\n",
       " 45: 260,\n",
       " 46: 247,\n",
       " 47: 218,\n",
       " 48: 205,\n",
       " 49: 165,\n",
       " 50: 156,\n",
       " 51: 154,\n",
       " 52: 111,\n",
       " 53: 98,\n",
       " 54: 90,\n",
       " 55: 86,\n",
       " 56: 87,\n",
       " 57: 60,\n",
       " 58: 68,\n",
       " 59: 65,\n",
       " 60: 50,\n",
       " 61: 48,\n",
       " 62: 51,\n",
       " 63: 21,\n",
       " 64: 26,\n",
       " 65: 42,\n",
       " 66: 24,\n",
       " 67: 29,\n",
       " 68: 21,\n",
       " 69: 23,\n",
       " 70: 19,\n",
       " 71: 10,\n",
       " 72: 17,\n",
       " 73: 21,\n",
       " 74: 16,\n",
       " 75: 12,\n",
       " 76: 7,\n",
       " 77: 7,\n",
       " 78: 6,\n",
       " 79: 4,\n",
       " 80: 10,\n",
       " 81: 2,\n",
       " 82: 6,\n",
       " 83: 8,\n",
       " 84: 7,\n",
       " 86: 4,\n",
       " 87: 3,\n",
       " 88: 1,\n",
       " 89: 7,\n",
       " 90: 3,\n",
       " 91: 2,\n",
       " 92: 2,\n",
       " 93: 5,\n",
       " 94: 1,\n",
       " 95: 2,\n",
       " 96: 1,\n",
       " 98: 2,\n",
       " 99: 3}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reorder_0 = train[train.reordered == 0]['_up_order_count']\n",
    "reorder_1 = train[train.reordered == 1]['_up_order_count']\n",
    "unique, counts = np.unique(reorder_0, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 179421,\n",
       " 2: 110266,\n",
       " 3: 76489,\n",
       " 4: 52016,\n",
       " 5: 37186,\n",
       " 6: 27547,\n",
       " 7: 21569,\n",
       " 8: 17354,\n",
       " 9: 13779,\n",
       " 10: 11301,\n",
       " 11: 9374,\n",
       " 12: 7825,\n",
       " 13: 6845,\n",
       " 14: 5806,\n",
       " 15: 4903,\n",
       " 16: 4340,\n",
       " 17: 3846,\n",
       " 18: 3251,\n",
       " 19: 2893,\n",
       " 20: 2512,\n",
       " 21: 2238,\n",
       " 22: 2026,\n",
       " 23: 1866,\n",
       " 24: 1615,\n",
       " 25: 1452,\n",
       " 26: 1304,\n",
       " 27: 1194,\n",
       " 28: 1070,\n",
       " 29: 991,\n",
       " 30: 929,\n",
       " 31: 818,\n",
       " 32: 678,\n",
       " 33: 627,\n",
       " 34: 594,\n",
       " 35: 543,\n",
       " 36: 497,\n",
       " 37: 451,\n",
       " 38: 397,\n",
       " 39: 374,\n",
       " 40: 362,\n",
       " 41: 313,\n",
       " 42: 294,\n",
       " 43: 255,\n",
       " 44: 238,\n",
       " 45: 244,\n",
       " 46: 206,\n",
       " 47: 189,\n",
       " 48: 158,\n",
       " 49: 155,\n",
       " 50: 140,\n",
       " 51: 119,\n",
       " 52: 117,\n",
       " 53: 98,\n",
       " 54: 70,\n",
       " 55: 80,\n",
       " 56: 51,\n",
       " 57: 57,\n",
       " 58: 51,\n",
       " 59: 39,\n",
       " 60: 41,\n",
       " 61: 45,\n",
       " 62: 40,\n",
       " 63: 39,\n",
       " 64: 24,\n",
       " 65: 32,\n",
       " 66: 15,\n",
       " 67: 26,\n",
       " 68: 17,\n",
       " 69: 15,\n",
       " 70: 22,\n",
       " 71: 21,\n",
       " 72: 13,\n",
       " 73: 12,\n",
       " 74: 10,\n",
       " 75: 11,\n",
       " 76: 11,\n",
       " 77: 4,\n",
       " 78: 5,\n",
       " 79: 15,\n",
       " 80: 8,\n",
       " 81: 14,\n",
       " 82: 5,\n",
       " 83: 3,\n",
       " 84: 8,\n",
       " 85: 3,\n",
       " 86: 4,\n",
       " 87: 5,\n",
       " 88: 6,\n",
       " 89: 2,\n",
       " 90: 2,\n",
       " 91: 3,\n",
       " 92: 7,\n",
       " 93: 2,\n",
       " 94: 8,\n",
       " 95: 3,\n",
       " 96: 1,\n",
       " 97: 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(reorder_1, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_0 = np.mean(reorder_0)\n",
    "average_1 = np.mean(reorder_1)\n",
    "print(average_0)\n",
    "print(average_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
